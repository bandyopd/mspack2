# rownames(Nstar) <- rownames(Is)
# performs isotonic regression
Nstar[, colnames(Is)] <- apply(Is, 2, function(y) gpava(z = cstimes, y = y, weights = (wICS * wZ))$x)
# Nstar <- apply(Nstar, 2, function(x) round(x*nind)) # Datta and Sundaram rounded these figures
# (kernel estimate) of the functions for estimating N and Y
tmp <- outer(timegrid, cstimes, Kh, h = bw)
# perform kernel smoothing -- counting process
Ns <- apply(Nstar, 2, function(pav) {
gc <- (tmp %*% wICS)/nind
(tmp %*% (pav * wICS))/gc
})
rownames(Ns) <- timegrid
## Computing the at-risk set
Ys <- matrix(0, nrow = length(timegrid), ncol = length(nt.states))
colnames(Ys) <- paste("Y", nodes(tree)[nt.states], sep = "")
# compute state indicator, I(Si(Ci) = j)
nstate <- length(unique(nodes(tree)))  # number of states in the multistate model
Ij <- t(sapply(df$state, function(x) {
a <- rep(0, nstate)
a[x] = 1
return(a)
}, simplify = TRUE))
colnames(Ij) <- paste("Y", nodes(tree), sep = "")
rownames(Ij) <- rownames(Is)
Ij <- Ij[, colnames(Ys)]
# computes the at-risk set via kernel smoothing include a PAV step for the transitions out of the initial state.
if (pavY) {
Ij <- apply(Ij, 2, function(y) (-gpava(z = cstimes, y = -y, weights = (wICS * wZ))$x))
Ys <- apply(Ij, 2, function(y) {
gc <- (tmp %*% (wICS * wZ))/nind
(tmp %*% (y * (wICS * wZ)))/gc
})
} else {
Ys <- apply(Ij, 2, function(y) {
gc <- (tmp %*% (wICS * wZ))/nind
(tmp %*% (y * (wICS * wZ)))/gc
})
}
colnames(Ys) <- paste("Y", nodes(tree)[nt.states], sep = "")
rownames(Ys) <- timegrid
rm(tmp)
# counts the number of actual transitions as defined in the column
dNs <- apply(Ns, 2, function(x) diff(x))
# adjust the at risk set
Ys <- Ys[-1, ]
# assign column names to dNs replicates the non-absorbing states by the number of edges out of each state gets the edges proceding
# out of each non-absorbing state
ds <- paste("dN", rep(nodes(tree)[nodes(tree) %in% names(nt.states)], lng), unlist(edges(tree)[nodes(tree) %in% names(nt.states)]))
colnames(dNs) <- ds
# remove rows with no transitions
rm.idx <- which(rowSums(dNs) <= 0)
if (length(rm.idx) != 0) {
dNs <- dNs[-rm.idx, ]  # remove rows with no transitions
Ys <- Ys[-rm.idx, ]
}
## compute state occupation probability
cum.tm <- diag(nstate)
colnames(cum.tm) <- rownames(cum.tm) <- nodes(tree)
ps <- matrix(NA, nrow = nrow(dNs), ncol = length(nodes(tree)))  # to store the state occupation prob. for each state at each event time
rownames(ps) <- rownames(dNs)
colnames(ps) <- paste("p", nodes(tree), sep = "")
# creates an array to store teh matrices of the estimates at each event time
all.dA <- all.I_dA <- all.ajs <- array(dim = c(nstate, nstate, nrow(dNs)), dimnames = list(rows = nodes(tree), cols = nodes(tree), dim = rownames(dNs)))
for (i in 1:nrow(dNs)) {
I_dA <- diag(nstate)
dA <- matrix(0, nrow = nstate, ncol = nstate)
colnames(I_dA) <- rownames(I_dA) <- colnames(dA) <- rownames(dA) <- nodes(tree)
idx <- which(dNs[i, ] > 0)
t.nam <- colnames(dNs)[idx]
tmp <- strsplit(t.nam, " ")
start <- sapply(tmp, function(x) x[2])
end <- sapply(tmp, function(x) x[3])
idxs <- matrix(as.numeric(c(start, end)), ncol = 2)
idxs2 <- matrix(as.numeric(c(start, start)), ncol = 2)
# computes the integrated transition hazard matrix
tmp <- dNs[i, idx]/Ys[i, paste("Y", start, sep = "")]
tmp[which(tmp > 1)] <- 1
dA[idxs] <- tmp
if (length(idx) == 1) {
tmp <- -dNs[i, idx]/Ys[i, paste("Y", start, sep = "")]
tmp[which(abs(tmp) > 1)] <- -1
dA[start, start] <- tmp
} else {
dA[idxs2] <- -rowSums(dA[start, ])
}
rm(tmp)
I_dA <- I_dA + dA  # I + dA matrix
all.dA[, , i] <- dA  # stores the dA matrix at time i
all.I_dA[, , i] <- I_dA  # stores the I_dA matrix at ime
cum.tm <- cum.tm %*% I_dA  # the product integral; the transition probability matrix at time i
all.ajs[, , i] <- cum.tm  # stores the transition probability matrix at time i
ps[i, ] <- start.probs %*% all.ajs[, , i]  # the state occupation prob at time i
}
rm.idx <- apply((is.na(ps) | is.infinite(ps)), 1, any)
ps <- ps[!rm.idx, ]
rm.idx <- apply((ps < 0 | ps > 1), 1, any)
ps <- ps[!rm.idx, ]
return(ps)
}
SOP <- function(data.type, dat, tree, start.probs, weight = "none", bw = NULL, ngrid = 1000, pavY = TRUE, cond = "none", Zval = NULL, cutoffs = NULL) {
# figure out the data type
arg0 <- c("uncorrelated", "cluster-correlated")
arg0chk <- charmatch(data.type, arg0)
if (is.na(arg0chk)) {
stop("data.type should be either 'uncorrelated' or 'cluster-correlated'")
}
# figure out the weight
arg1 <- c("ICS", "none")
arg1chk <- charmatch(weight, arg1)
if (is.na(arg1chk)) {
stop("weight should be either 'ICS' or 'none'")
}
if (any(unique(dat$state) == 0)) {
stop("Do not name any state as '0', the initial node should be '1' ")
}
if (!all(as.character(unique(dat$state)) %in% nodes(tree))) {
stop("states in 'dat' object do not match with states in the 'tree' object ")
}
if (weight == "none")
weight <- 1
if (cond == "none")
cond <- NULL
if (data.type == "uncorrelated") {
res <- curr_stat_unclust(dat = dat, tree = tree, start.probs = start.probs, bw = bw, ngrid = ngrid, pavY = pavY, cond = cond, Zval = Zval)
} else if (data.type == "cluster-correlated") {
res <- curr_stat(dat = dat, tree = tree, start.probs = start.probs, weight = weight, bw = bw, ngrid = ngrid, pavY = pavY, cond = cond,
Zval = Zval)
}
# get the estimates at specific time points
res <- data.frame(time = as.numeric(row.names(res)), res)
row.names(res) <- NULL
if (is.null(cutoffs)) {
return(res)
} else {
res <- getProbs(fit = res, cutoffs = cutoffs)
return(res)
}
}
SOP(data.type='cluster-correlated',dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight='none', pavY=TRUE, cond='none', Zval=NULL,
cutoffs = seq(from=0.1, to=0.9, length.out=10))
m <- 5
cdat <- lapply(1:m, function(x){
ni <- rpois(1, 10) # cluster size
cID <- rep(x,ni) # cluster ids
time <- rweibull(x, shape=3, scale=5) # inspection time
state <- sample(c(as.numeric(nodes(tree))), ni, replace=T) # state at inspection time
csize <- rep(ni, ni) # cluster sizes
data.frame(cID=cID, time=times, state=state, csize=csize)
})
cdat <- do.call(rbind, cdat)
cdat$id <- 1:nrow(cdat)
SOP(data.type='cluster-correlated',dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight='none', pavY=TRUE, cond='none', Zval=NULL,
cutoffs = seq(from=0.1, to=0.9, length.out=10))
SOP(data.type='cluster-correlated',dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight='none', pavY=TRUE, cond='none', Zval=NULL,
cutoffs = seq(from=0.1, to=0.9, length.out=10))
dat=cdat
# data with sorted inspection times
df <- with(dat, dat[order(dat$time), ])
cstimes <- df$time
cstimes
m <- 5
cdat <- lapply(1:m, function(x){
ni <- rpois(1, 10) # cluster size
cID <- rep(x,ni) # cluster ids
time <- rweibull(ni, shape=3, scale=5) # inspection time
state <- sample(c(as.numeric(nodes(tree))), ni, replace=T) # state at inspection time
csize <- rep(ni, ni) # cluster sizes
data.frame(cID=cID, time=times, state=state, csize=csize)
})
cdat <- do.call(rbind, cdat)
cdat$id <- 1:nrow(cdat)
ni <- rpois(1, 10)+2 # cluster size
ni
x=1
cID <- rep(x,ni) # cluster ids
cID
time <- rweibull(ni, shape=3, scale=5) # inspection time
time
state <- sample(c(as.numeric(nodes(tree))), ni, replace=T) # state at inspection time
state
csize <- rep(ni, ni) # cluster sizes
csize
data.frame(cID=cID, time=times, state=state, csize=csize)
m <- 5
cdat <- lapply(1:m, function(x){
ni <- rpois(1, 10)+2 # cluster size
cID <- rep(x,ni) # cluster ids
time <- rweibull(ni, shape=3, scale=5) # inspection time
state <- sample(c(as.numeric(nodes(tree))), ni, replace=T) # state at inspection time
csize <- rep(ni, ni) # cluster sizes
data.frame(cID=cID, time=time, state=state, csize=csize)
})
cdat <- do.call(rbind, cdat)
cdat$id <- 1:nrow(cdat)
SOP(data.type='cluster-correlated',dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight='none', pavY=TRUE, cond='none', Zval=NULL,
cutoffs = seq(from=0.1, to=0.9, length.out=10))
SOP(data.type='cluster-correlated',dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight='none', pavY=TRUE, cond='none', Zval=NULL,
cutoffs = seq(from=min(cdat$time), to=max(cdat$time), length.out=10))
rm(list = ls())
library(devtools)
library(Rdpack)
WD2 <- "C:/Users/sanyasosamuel/Desktop/package/mspack2"
setwd(WD2)
formatR::tidy_dir("R")
# Step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
# Step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
# Step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
devtools::check() ## default argument is pkg = ".", current working directory
Nodes <- c("1","2","3")
Edges <- list("1"=list(edges=c("2")), "2"=list(edges=c("3")),"3"=list(edges=NULL))
##'
##' ## Constructs the tree
tree <- new("graphNEL", nodes=Nodes, edgeL=Edges, edgemode="directed")
start.probs <- c(1, 0, 0)  # assumes all subjects start from state 1 and time 0
names(start.probs) <- nodes(tree)
m <- 5
cdat <- lapply(1:m, function(x){
ni <- rpois(1, 10)+2 # cluster size
cID <- rep(x,ni) # cluster ids
time <- rweibull(ni, shape=3, scale=5) # inspection time
state <- sample(c(as.numeric(Nodes)), ni, replace=T) # state at inspection time
csize <- rep(ni, ni) # cluster sizes
data.frame(cID=cID, time=time, state=state, csize=csize)
})
cdat <- do.call(rbind, cdat)
cdat$id <- 1:nrow(cdat)
View(cdat)
c(as.numeric(Nodes))
?sampel
?sample
?rep
?rpois
# Step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
devtools::check() ## default argument is pkg = ".", current working directory
# Step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
devtools::check() ## default argument is pkg = ".", current working directory
# Step  - Builds the package
# This step will generate a .tar.gz package (a zip file)
setwd(WD2)
devtools::build() ## default argument is pkg = ".", current working directory
# Step - Install the package
# To install package, set wd in the home directory of the
# Built package
setwd(WD2)
devtools::install() ## default argument is pkg = ".", current working directory
library(mspack2)
mspack2::CSdata
data(CSdata)
rm(list = ls())
library(mspack2)
?mspack2::CSdata
head(CSdata)
?SOP
GAAD
?GAAD
CSdata <- data(CSdata)
head(CSdata)
CSdata <- data(CSdata)
CSdata
GAAD
## Test the package
rm(list = ls())
library(mspack2)
?mspack2::CSdata
head(CSdata)
?SOP
# grab the array id value from the environment variable passed from sbatch
arr_id <- as.numeric(Sys.getenv('SLURM_ARRAY_TASK_ID'))
print(arr_id)
inSLURM <- (Sys.getenv("SLURM_JOB_ID") != "") # true only if a SLURM job
if(!inSLURM) arr_id <- 1
subpath <- ifelse(inSLURM, "/home/sanyasosamuel","U:")
# load functions for simulating the current status data and
# estimating state occupation probability
source(paste(subpath,"/survival/CurrentStatus/unclustered/funcs.R", sep=""))
seed <- sample(300000,1)
m <- 200 # no. of clusters.
m <- 30 # no. of clusters.
## a progressive 3-state tracking model
Nodes <- c("1","2","3")
Edges <- list("1"=list(edges=c("2")),
"2"=list(edges=c("3")),
"3"=list(edges=NULL))
tree <- new("graphNEL", nodes=Nodes, edgeL=Edges, edgemode="directed")
start.probs <- c(1, 0, 0)  # assumes all subjects start from state 1 and time 0
names(start.probs) <- nodes(tree)
# parameters for data simulation
gammas <- c(1.5, 3, -3, 0); names(gammas) <- c("gamma1","gamma2","gamma3","gamma4")
# NB: sigA controls the variation of the cluster sizes while sigE controls censoring and also affects the shape of the plots
sig <- c(0.15, 0.5, 0.3, 0.15); names(sig) <- c("sig2", "sigA", "sigE", "sigG")
par12 <- c(0.0, 0.25, 0.0, sig["sigE"]) # Lognormal dist pars and coefficient of Z in the haz for 1 --> 2
names(par12) <- c("beta0", "beta1", "beta2", "sig")
par23 <- par12
cpar <- c(3, 2.5) # parameters for the distribution of the current status data
# cpar <- c(NA,NA) # parameters for the distribution of the current status data
lambda <- NULL
preds <- c("Z1")
# generates data from a progressive 3-state tracking model with both cluster & subj-level covariates
cdat <- simLN(m=m, par12=par12, par23=par23, preds=preds, sig, gammas,
lambda=lambda, cons=2, cpar=cpar)
cdat <- cdat$data
names(cdat)[which(names(cdat) == "state")] <- "state"
table(cdat$state)
View(cdat)
# set covariates and other information aside
covs <- cdat[, !(names(cdat) %in% c("time","state"))]
start.probs
tree
res <- SOP(data.type = 'cluster-correlated', dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight="ICS", pavY = T)
View(res)
?CSdata
CSdata
## Test the package
rm(list = ls())
# Remove the package
remove.packages("mspack2")
?SOP
rm(list = ls())
library(devtools)
library(Rdpack)
WD2 <- "C:/Users/sanyasosamuel/Desktop/package/mspack2"
setwd(WD2)
formatR::tidy_dir("R")
### step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
## step -loads external data
# GAAD <- load(file = "C:/Users/sanyasosamuel/Desktop/package/GAAD.rda")
# GAAD <- dat
# usethis::use_data(GAAD, overwrite = TRUE)
#
# # loads simulated data
CSdata <- load(file = "C:/Users/sanyasosamuel/Desktop/package/CSdata.rda")
CSdata <- dat
colnames(CSdata)[which(colnames(CSdata) == "times")] <- "time"
View(CSdata)
usethis::use_data(CSdata, overwrite = TRUE)
## step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
## step - Checks the package
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
## step  - Builds the package
# This step will generate a .tar.gz package (a zip file)
setwd(WD2)
devtools::build() ## default argument is pkg = ".", current working directory
## step - Install the package
# To install package, set wd in the home directory of the
# Built package
setwd(WD2)
devtools::install() ## default argument is pkg = ".", current working directory
## Test the package
rm(list = ls())
library(mspack2)
?mspack2::CSdata
head(CSdata)
?SOP
## Test the package
rm(list = ls())
library(mspack2)
?mspack2::CSdata
# grab the array id value from the environment variable passed from sbatch
arr_id <- as.numeric(Sys.getenv('SLURM_ARRAY_TASK_ID'))
print(arr_id)
inSLURM <- (Sys.getenv("SLURM_JOB_ID") != "") # true only if a SLURM job
if(!inSLURM) arr_id <- 1
subpath <- ifelse(inSLURM, "/home/sanyasosamuel","U:")
# load functions for simulating the current status data and
# estimating state occupation probability
source(paste(subpath,"/survival/CurrentStatus/unclustered/funcs.R", sep=""))
seed <- sample(300000,1)
m <- 30 # no. of clusters.
## a progressive 3-state tracking model
Nodes <- c("1","2","3")
Edges <- list("1"=list(edges=c("2")),
"2"=list(edges=c("3")),
"3"=list(edges=NULL))
tree <- new("graphNEL", nodes=Nodes, edgeL=Edges, edgemode="directed")
start.probs <- c(1, 0, 0)  # assumes all subjects start from state 1 and time 0
names(start.probs) <- nodes(tree)
# parameters for data simulation
gammas <- c(1.5, 3, -3, 0); names(gammas) <- c("gamma1","gamma2","gamma3","gamma4")
# NB: sigA controls the variation of the cluster sizes while sigE controls censoring and also affects the shape of the plots
sig <- c(0.15, 0.5, 0.3, 0.15); names(sig) <- c("sig2", "sigA", "sigE", "sigG")
par12 <- c(0.0, 0.25, 0.0, sig["sigE"]) # Lognormal dist pars and coefficient of Z in the haz for 1 --> 2
names(par12) <- c("beta0", "beta1", "beta2", "sig")
par23 <- par12
cpar <- c(3, 2.5) # parameters for the distribution of the current status data
# cpar <- c(NA,NA) # parameters for the distribution of the current status data
lambda <- NULL
preds <- c("Z1")
# generates data from a progressive 3-state tracking model with both cluster & subj-level covariates
cdat <- simLN(m=m, par12=par12, par23=par23, preds=preds, sig, gammas,
lambda=lambda, cons=2, cpar=cpar)
cdat <- cdat$data
names(cdat)[which(names(cdat) == "state")] <- "state"
table(cdat$state)
# set covariates and other information aside
covs <- cdat[, !(names(cdat) %in% c("time","state"))]
res <- SOP(data.type = 'cluster-correlated', dat=cdat, tree=tree, start.probs=start.probs,
ngrid=1000, weight="ICS", pavY = T)
View(res)
library(mspack2)
?mspack2::CSdata
head(CSdata)
SOP
?SOP
?GAAD
## Test the package
rm(list = ls())
# Remove the package
remove.packages("mspack2")
rm(list = ls())
library(devtools)
library(Rdpack)
## step 1 - create a new R package
WD <- "C:/Users/sanyasosamuel/Desktop/package"
setwd(WD)
WD2 <- "C:/Users/sanyasosamuel/Desktop/package/mspack2"
setwd(WD2)
formatR::tidy_dir("R")
## step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
## step - Checks the package
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
## step  - Builds the package
# This step will generate a .tar.gz package (a zip file)
setwd(WD2)
devtools::build() ## default argument is pkg = ".", current working directory
## step - Install the package
# To install package, set wd in the home directory of the
# Built package
setwd(WD2)
devtools::install() ## default argument is pkg = ".", current working directory
## Test the package
rm(list = ls())
library(mspack2)
?mspack2::CSdata
head(CSdata)
?SOP
## Test the package
rm(list = ls())
remove.packages("mspack2")
rm(list = ls())
library(devtools)
library(Rdpack)
## step 1 - create a new R package
WD <- "C:/Users/sanyasosamuel/Desktop/package"
setwd(WD)
WD2 <- "C:/Users/sanyasosamuel/Desktop/package/mspack2"
setwd(WD2)
formatR::tidy_dir("R")
### step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
## step - Checks the package
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
## step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
## step - Checks the package
setwd(WD2)
devtools::check() ## default argument is pkg = ".", current working directory
## step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
devtools::check() ## default argument is pkg = ".", current working directory
## step  - Builds the package
# This step will generate a .tar.gz package (a zip file)
setwd(WD2)
devtools::build() ## default argument is pkg = ".", current working directory
## step - Install the package
## To install package, set wd in the home directory of the
## Built package
setwd(WD2)
devtools::install() ## default argument is pkg = ".", current working directory
## Test the package
rm(list = ls())
library(mspack2)
?mspack2::CSdata
head(CSdata)
?SOP
remove.packages("mspack2")
rm(list = ls())
library(devtools)
library(Rdpack)
## step 1 - create a new R package
WD <- "C:/Users/sanyasosamuel/Desktop/package"
setwd(WD)
WD2 <- "C:/Users/sanyasosamuel/Desktop/package/mspack2"
setwd(WD2)
formatR::tidy_dir("R")
### step - Generate R documentation
devtools::document() ## default argument is pkg = ".", current working directory
usethis::use_vignette("mspack2")
devtools::build_vignettes()
.Last.error.trace
## install the package from github
devtools::install_github("samuelanyaso/mspack2",auth_token = "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")
